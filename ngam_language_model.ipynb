{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Odia n-gram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict\n",
    "import dill as pickle\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from indicnlp.tokenize.indic_tokenize import trivial_tokenize_indic\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "random_seed = 123\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "read lines from file: 100%|██████████| 3594672/3594672 [00:02<00:00, 1736691.00it/s]\n"
     ]
    }
   ],
   "source": [
    "data_filepath = os.path.join('data/or')\n",
    "assert os.path.isfile(data_filepath)  # sanity check\n",
    "with open(data_filepath, 'r', encoding='utf-8') as f:\n",
    "    lines = [s.strip() for s in tqdm(f.readlines(), desc='read lines from file')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text: List[str]) -> List[List[str]]:\n",
    "    \"\"\"Tokenize text\"\"\"\n",
    "    return [trivial_tokenize_indic(sample) for sample in tqdm(text, desc='tokenize', unit=' samples')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenize: 100%|██████████| 3594672/3594672 [01:27<00:00, 41267.79 samples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenize_text(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "num_val = 500\n",
    "\n",
    "# shuffle\n",
    "random.shuffle(tokenized_text)\n",
    "\n",
    "# split\n",
    "tokenized_train, tokenized_val = tokenized_text[:-num_val], tokenized_text[-num_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compute vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_vocab(tok_text: List[List[str]]) -> List[str]:\n",
    "    return list(set(\n",
    "        [tok for tokens in tqdm(tok_text, unit=' samples') for tok in tokens]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3594672/3594672 [00:05<00:00, 600921.22 samples/s]\n"
     ]
    }
   ],
   "source": [
    "odia_vocab = compute_vocab(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 778862\n"
     ]
    }
   ],
   "source": [
    "print('vocab size:', len(odia_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## N-Gram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NGramLM(object):\n",
    "    def __init__(self, n: int, delta: float, vocab: List[str]):\n",
    "        self.n = n\n",
    "        self.delta = delta\n",
    "        self.count = defaultdict(lambda: defaultdict(float))\n",
    "        self.total = defaultdict(float)\n",
    "        self.vocab = vocab\n",
    "        if '<eos>' not in self.vocab:\n",
    "            self.vocab.append('<eos>')\n",
    "        self.vsize = len(vocab)\n",
    "\n",
    "    def estimate(self, sequences: List[List[str]]) -> None:\n",
    "        for sequence_raw in tqdm(sequences, unit=' sequences', desc='LM estimate'):\n",
    "            sequence = ['<bos>'] * (self.n - 1) + sequence_raw + ['<eos>']\n",
    "            for i in range(len(sequence) - self.n + 1):\n",
    "                ngram = tuple(sequence[i:i + self.n])\n",
    "                prefix, word = ngram[:-1], ngram[-1]\n",
    "                self.count[prefix][word] += 1\n",
    "                self.total[prefix] += 1\n",
    "\n",
    "    def sequence_logp(self, sequence_raw: List[str]) -> float:\n",
    "        \"\"\"Compute perplexity for a sequence\"\"\"\n",
    "        sequence = ['<bos>'] * (self.n - 1) + sequence_raw + ['<eos>']\n",
    "        total_logp = 0\n",
    "        for i in range(len(sequence) - self.n + 1):\n",
    "            ngram = tuple(sequence[i:i + self.n])\n",
    "            prefix = ngram[:-1]\n",
    "            word = ngram[-1]\n",
    "            logp = np.log2((self.delta + self.count[prefix][word]) /\n",
    "                           (self.total[prefix] + self.delta * self.vsize))\n",
    "            total_logp += logp\n",
    "        return total_logp\n",
    "\n",
    "    def perplexity(self, sequences: List[List[str]]) -> float:\n",
    "        \"\"\"Compute perplexity for multiple sequences\"\"\"\n",
    "        n_total = 0\n",
    "        logp_total = 0\n",
    "        for sequence_raw in tqdm(sequences, unit=' sequences'):\n",
    "            logp_total += self.sequence_logp(sequence_raw)\n",
    "            n_total += len(sequence_raw) + 1  # add 1 for <eos>\n",
    "        ppl = 2 ** (- (1.0 / n_total) * logp_total)  # the log needs to be in base 2!\n",
    "        return ppl\n",
    "\n",
    "    def generate(self, context: List[str] = None) -> str:\n",
    "        \"\"\"Generate text\"\"\"\n",
    "\n",
    "        if context is None:\n",
    "            prefix = None\n",
    "            context = ['<bos>'] * (self.n - 1)\n",
    "        elif len(context) < self.n - 1:\n",
    "            prefix = copy.deepcopy(context)\n",
    "            context = ['<bos>'] * (self.n - 1 - len(context)) + context\n",
    "        elif len(context) > self.n - 1:\n",
    "            prefix = copy.deepcopy(context)\n",
    "            context = context[-(self.n - 1):]\n",
    "        else:  # len(context) = self.n - 1\n",
    "            prefix = None\n",
    "\n",
    "        output = context\n",
    "        while output[-1] != '<eos>':\n",
    "            # Form conditional distribution to sample from\n",
    "            probs, tokens = [], []\n",
    "            for token in self.count[tuple(context)]:\n",
    "                p = self.count[tuple(context)][token] / self.total[tuple(context)]\n",
    "                probs.append(p)\n",
    "                tokens.append(token)\n",
    "            # Sample\n",
    "            wt = np.random.choice(tokens, p=probs)\n",
    "            output = output + [wt]\n",
    "            context = context[1:] + [wt]\n",
    "        if prefix is not None:\n",
    "            return ' '.join(prefix + output[self.n - 1:])\n",
    "        else:\n",
    "            return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LM estimate: 100%|██████████| 3594172/3594172 [02:56<00:00, 20323.24 sequences/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 11151.86 sequences/s]\n"
     ]
    }
   ],
   "source": [
    "ns = [3]\n",
    "deltas = [0.001]\n",
    "\n",
    "lm_odia = {}\n",
    "ppl_odia = {}\n",
    "\n",
    "for n in ns:\n",
    "    for delta in deltas:\n",
    "        lm_odia[n, delta] = NGramLM(n=n, delta=delta, vocab=odia_vocab,)\n",
    "\n",
    "        # estimate\n",
    "        lm_odia[n, delta].estimate(tokenized_train)\n",
    "\n",
    "        # compute perplexity\n",
    "        ppl_odia[n, delta] = lm_odia[n, delta].perplexity(tokenized_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generate Odia text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "Odia LM, n = 3, delta = 0.0010\n",
      "<bos> <bos> ତେବେ ଜୁଲାଇରୁ ରୋଗୀସଂଖ୍ୟା ବଢିବାରେ ଲାଗିଛି । <eos>\n",
      "<bos> <bos> ଆଗାମୀ ୫ ବର୍ଷ ପୂର୍ବେ ନରେନ୍ଦ୍ର୍ର ମୋଦି ପ୍ରଧାନମନ୍ତ୍ରୀ ଓ ରାଜ୍ୟ ବାହାରେ ପଢୁଥିବା ଜଣେ ଛାତ୍ର ବାନ୍ତି ହେବାରୁ ପ୍ରଥମେ କୋଷାଗମୁଡା ଓ ପରେ କାଳିଆ ସେ ଅଞ୍ଚଳରେ ଖଜୁରି ତାଡ଼ି ସଂଗ୍ରହକୁ ସରକାର ସମ୍ପୂର୍ଣ୍ଣ ବିଫଳ ହୋଇଛନ୍ତି । <eos>\n",
      "<bos> <bos> କେବଳ ଏତିକି ନହେଁ ବରଂ ୟୁନିଅନ ବ୍ୟାଙ୍କ , ଆଇଡିବିଆଇ ବ୍ୟାଙ୍କ କର୍ମଚାରୀ 0 ସେୟାର ଓ୍ବାସିଂଟନ୍ / ଜେରୁଜେଲମ୍ଃ ବୁଧବାର ଦିନ କର୍ଣ୍ଣାଟକ ଗସ୍ତରେ ଯାଇଥିଲେ । <eos>\n",
      "<bos> <bos> ୨୧ ତାରିଖରେ ଭୁବନେଶ୍ୱର ଆସି ମୋ ଚେୟାର୍ ପାଖରେ ବସ । <eos>\n",
      "<bos> <bos> କୂଳଠାରୁ ବହୁ ଦୂରରେ ରହିଯାଇଥିଲା । <eos>\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for n in ns:\n",
    "    for delta in deltas:\n",
    "        print(89 * '-')\n",
    "        print(f'Odia LM, n = {n}, delta = {delta:.4f}')\n",
    "        for _ in range(5):\n",
    "            print(lm_odia[n, delta].generate())\n",
    "        print(89 * '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lm_odia[3, deltas[0]].generate(context=['ଦୂରରେ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-27-fab5aa4822df>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'ngram.lm.pkl'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'wb'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[0mpickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlm_odia\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdeltas\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\site-packages\\dill\\_dill.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol, byref, fmode, recurse, **kwds)\u001B[0m\n\u001B[0;32m    275\u001B[0m     \u001B[0m_kwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbyref\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbyref\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecurse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mrecurse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 276\u001B[1;33m     \u001B[0mPickler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0m_kwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    277\u001B[0m     \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\site-packages\\dill\\_dill.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    497\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 498\u001B[1;33m             \u001B[0mStockPickler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    499\u001B[0m         \u001B[0mstack\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# clear record of 'recursion-sensitive' pickled objects\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\pickle.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    408\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart_framing\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 409\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    410\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSTOP\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\pickle.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(self, obj, save_persistent_id)\u001B[0m\n\u001B[0;32m    520\u001B[0m         \u001B[1;31m# Save the reduce() output and finally memoize the object\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 521\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_reduce\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mrv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    522\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\pickle.py\u001B[0m in \u001B[0;36msave_reduce\u001B[1;34m(self, func, args, state, listitems, dictitems, obj)\u001B[0m\n\u001B[0;32m    633\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mstate\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 634\u001B[1;33m             \u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    635\u001B[0m             \u001B[0mwrite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBUILD\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\pickle.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(self, obj, save_persistent_id)\u001B[0m\n\u001B[0;32m    475\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mf\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 476\u001B[1;33m             \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# Call unbound method with explicit self\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    477\u001B[0m             \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\site-packages\\dill\\_dill.py\u001B[0m in \u001B[0;36msave_module_dict\u001B[1;34m(pickler, obj)\u001B[0m\n\u001B[0;32m    989\u001B[0m             \u001B[0mpickler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_session\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 990\u001B[1;33m         \u001B[0mStockPickler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpickler\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    991\u001B[0m         \u001B[0mlog\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"# D2\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\pickle.py\u001B[0m in \u001B[0;36msave_dict\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    820\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmemoize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 821\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_batch_setitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    822\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\pickle.py\u001B[0m in \u001B[0;36m_batch_setitems\u001B[1;34m(self, items)\u001B[0m\n\u001B[0;32m    846\u001B[0m                     \u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 847\u001B[1;33m                     \u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    848\u001B[0m                 \u001B[0mwrite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSETITEMS\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\pickle.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(self, obj, save_persistent_id)\u001B[0m\n\u001B[0;32m    520\u001B[0m         \u001B[1;31m# Save the reduce() output and finally memoize the object\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 521\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_reduce\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mrv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    522\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\pickle.py\u001B[0m in \u001B[0;36msave_reduce\u001B[1;34m(self, func, args, state, listitems, dictitems, obj)\u001B[0m\n\u001B[0;32m    630\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mdictitems\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 631\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_batch_setitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdictitems\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    632\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\pytorch1_1\\lib\\pickle.py\u001B[0m in \u001B[0;36m_batch_setitems\u001B[1;34m(self, items)\u001B[0m\n\u001B[0;32m    841\u001B[0m             \u001B[0mtmp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mislice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mit\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_BATCHSIZE\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 842\u001B[1;33m             \u001B[0mn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtmp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    843\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mn\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-27-fab5aa4822df>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# dump lm to file\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'ngram.lm.pkl'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'wb'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[0mpickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlm_odia\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdeltas\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# dump lm to file\n",
    "with open(os.path.join('ngram.lm.pkl'), 'wb') as f:\n",
    "    pickle.dump(lm_odia[3, deltas[0]], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}