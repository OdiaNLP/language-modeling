{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Odia n-gram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "from indicnlp.tokenize.indic_tokenize import trivial_tokenize_indic\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "random_seed = 123\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "read lines from file: 100%|██████████| 3594672/3594672 [00:02<00:00, 1642670.08it/s]\n"
     ]
    }
   ],
   "source": [
    "data_filepath = os.path.join('data/or')\n",
    "assert os.path.isfile(data_filepath)  # sanity check\n",
    "with open(data_filepath, 'r', encoding='utf-8') as f:\n",
    "    lines = [s.strip() for s in tqdm(f.readlines(), desc='read lines from file')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text: List[str]) -> List[List[str]]:\n",
    "    \"\"\"Tokenize text\"\"\"\n",
    "    return [trivial_tokenize_indic(sample) for sample in tqdm(text, desc='tokenize', unit=' samples')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenize: 100%|██████████| 10000/10000 [00:00<00:00, 42551.87 samples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenized_text = tokenize_text(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "num_val = 500\n",
    "\n",
    "# shuffle\n",
    "random.shuffle(tokenized_text)\n",
    "\n",
    "# split\n",
    "tokenized_train, tokenized_val = tokenized_text[:-num_val], tokenized_text[-num_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compute vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_vocab(tok_text: List[List[str]]) -> List[str]:\n",
    "    return list(set(\n",
    "        [tok for tokens in tqdm(tok_text, unit=' samples') for tok in tokens]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 716191.52 samples/s]\n"
     ]
    }
   ],
   "source": [
    "odia_vocab = compute_vocab(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 20216\n"
     ]
    }
   ],
   "source": [
    "print('vocab size:', len(odia_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## N-Gram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NGramLM(object):\n",
    "    def __init__(self, n: int, delta: float, vocab: List[str]):\n",
    "        self.n = n\n",
    "        self.delta = delta\n",
    "        self.count = defaultdict(lambda: defaultdict(float))\n",
    "        self.total = defaultdict(float)\n",
    "        self.vocab = vocab\n",
    "        if '<eos>' not in self.vocab:\n",
    "            self.vocab.append('<eos>')\n",
    "        self.vsize = len(vocab)\n",
    "\n",
    "    def estimate(self, sequences: List[List[str]]) -> None:\n",
    "        for sequence_raw in tqdm(sequences, unit=' sequences', desc='LM estimate'):\n",
    "            sequence = ['<bos>'] * (self.n - 1) + sequence_raw + ['<eos>']\n",
    "            for i in range(len(sequence) - self.n + 1):\n",
    "                ngram = tuple(sequence[i:i + self.n])\n",
    "                prefix, word = ngram[:-1], ngram[-1]\n",
    "                self.count[prefix][word] += 1\n",
    "                self.total[prefix] += 1\n",
    "\n",
    "    def sequence_logp(self, sequence_raw: List[str]) -> float:\n",
    "        \"\"\"Compute perplexity for a sequence\"\"\"\n",
    "        sequence = ['<bos>'] * (self.n - 1) + sequence_raw + ['<eos>']\n",
    "        total_logp = 0\n",
    "        for i in range(len(sequence) - self.n + 1):\n",
    "            ngram = tuple(sequence[i:i + self.n])\n",
    "            prefix = ngram[:-1]\n",
    "            word = ngram[-1]\n",
    "            logp = np.log2((self.delta + self.count[prefix][word]) /\n",
    "                           (self.total[prefix] + self.delta * self.vsize))\n",
    "            total_logp += logp\n",
    "        return total_logp\n",
    "\n",
    "    def perplexity(self, sequences: List[List[str]]) -> float:\n",
    "        \"\"\"Compute perplexity for multiple sequences\"\"\"\n",
    "        n_total = 0\n",
    "        logp_total = 0\n",
    "        for sequence_raw in tqdm(sequences, unit=' sequences'):\n",
    "            logp_total += self.sequence_logp(sequence_raw)\n",
    "            n_total += len(sequence_raw) + 1  # add 1 for <eos>\n",
    "        ppl = 2 ** (- (1.0 / n_total) * logp_total)  # the log needs to be in base 2!\n",
    "        return ppl\n",
    "\n",
    "    def generate(self, context: List[str] = None) -> str:\n",
    "        \"\"\"Generate text\"\"\"\n",
    "\n",
    "        if context is None:\n",
    "            prefix = None\n",
    "            context = ['<bos>'] * (self.n - 1)\n",
    "        elif len(context) < self.n - 1:\n",
    "            prefix = copy.deepcopy(context)\n",
    "            context = ['<bos>'] * (self.n - 1 - len(context)) + context\n",
    "        elif len(context) > self.n - 1:\n",
    "            prefix = copy.deepcopy(context)\n",
    "            context = context[-(self.n - 1):]\n",
    "        else:  # len(context) = self.n - 1\n",
    "            prefix = None\n",
    "\n",
    "        output = context\n",
    "        while output[-1] != '<eos>':\n",
    "            # Form conditional distribution to sample from\n",
    "            probs, tokens = [], []\n",
    "            for token in self.count[tuple(context)]:\n",
    "                p = self.count[tuple(context)][token] / self.total[tuple(context)]\n",
    "                probs.append(p)\n",
    "                tokens.append(token)\n",
    "            # Sample\n",
    "            wt = np.random.choice(tokens, p=probs)\n",
    "            output = output + [wt]\n",
    "            context = context[1:] + [wt]\n",
    "        if prefix is not None:\n",
    "            return ' '.join(prefix + output[self.n - 1:])\n",
    "        else:\n",
    "            return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LM estimate: 100%|██████████| 9500/9500 [00:00<00:00, 20872.94 sequences/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 17905.55 sequences/s]\n"
     ]
    }
   ],
   "source": [
    "ns = [3]\n",
    "deltas = [0.001]\n",
    "\n",
    "lm_odia = {}\n",
    "ppl_odia = {}\n",
    "\n",
    "for n in ns:\n",
    "    for delta in deltas:\n",
    "        lm_odia[n, delta] = NGramLM(n=n, delta=delta, vocab=odia_vocab, )\n",
    "\n",
    "        # estimate\n",
    "        lm_odia[n, delta].estimate(tokenized_train)\n",
    "\n",
    "        # compute perplexity\n",
    "        ppl_odia[n, delta] = lm_odia[n, delta].perplexity(tokenized_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generate Odia text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "Odia LM, n = 3, delta = 0.0010\n",
      "<bos> <bos> ଶାହାଙ୍କ ଗସ୍ତ ଲାଗି ରାଜ୍ୟ ସରକାରଙ୍କ ପାଖରେ ଜନସାଧାରଣଙ୍କ ସ୍ୱାର୍ଥର ସୁରକ୍ଷା ପାଇଁ ଦୃଢ଼ ପଦକ୍ଷେପ ଗ୍ରହଣ କରିବାକୁ ସାଧାରଣରେ ଦାବି ହୋଉଛି । <eos>\n",
      "<bos> <bos> ବିଭାଗୀୟ ଉଚ୍ଚ କର୍ତ୍ତୃପକ୍ଷ ତୁରନ୍ତ ଭଦ୍ରେଶ୍ୱର ପଞ୍ଚାୟତରେ ହୋଇଥିବା ପ୍ରଧାନମନ୍ତ୍ରୀ ଆବାସ ଯୋଜନାରେ ଘର ଖଣ୍ଡିଏ ଯୋଗାଇ ଦେବା ସହିତ ମୁସଲିମଙ୍କୁ ଅନ୍ୟତ୍ର ବିକଳ୍ପ ଜାଗା ପ୍ରଦାନ ପାଇଁ ନିଦେ୍ର୍ଦଶ ଥିଲା ଏହା ମଧ୍ୟ କହିଛନ୍ତି କେବଳ ଭାରତରେ ନୁହେଁ ବିଶ୍ୱ ବଜାରରେ ମଧ୍ୟ ଏହି ଯୋଜନାରେ ଆଉ କାହାରିକୁ ଗ୍ୟାସ ସଂଯୋଗ ଲୁଟି ନେଇଥିଲେ । <eos>\n",
      "<bos> <bos> ସେଥିପାଇଁ ଡାକ୍ତରଙ୍କୁ ଦ୍ୱିତୀୟ ଭଗବାନ ବୋଲି କୁହାଯାଇଥାଏ । <eos>\n",
      "<bos> <bos> ପ୍ରାକୃତିକ ପ୍ରଣାଳୀରେ ପ୍ରସ୍ତୁତ ପ୍ରସାଧାନରେ ଶ୍ରୀବିଗ୍ରହମାନଙ୍କ ଶ୍ରୀମୁଖକୁ ଶୃଙ୍ଗାର କରାଯିବ । <eos>\n",
      "<bos> <bos> 64 ପ୍ରସ୍ତୁତି ପ୍ରଣାଳୀ ପ୍ରଥମେ ପନିରକୁ ଛୋଟ ଛୋଟ କରି ସେଥିରେ କଟା ପିଆଜ , କଟା ଅଦା , କଟା ପି଼ଆଜ , ତେଜପତ୍ର , କଟା କଞ୍ଚା ଲଙ୍କା , କଟା କଞ୍ଚା ଲଙ୍କା ଓ କଟା ରସୁଣକୁ ଭାଜି ପୁର ପ୍ରସ୍ତୁତ କରନ୍ତୁ । <eos>\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for n in ns:\n",
    "    for delta in deltas:\n",
    "        print(89 * '-')\n",
    "        print(f'Odia LM, n = {n}, delta = {delta:.4f}')\n",
    "        for _ in range(5):\n",
    "            print(lm_odia[n, delta].generate())\n",
    "        print(89 * '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-27-6223da5dd75b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mlm_odia\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdeltas\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontext\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'ଦୂରରେ'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-18-640cc2f85eb0>\u001B[0m in \u001B[0;36mgenerate\u001B[1;34m(self, context)\u001B[0m\n\u001B[0;32m     66\u001B[0m                 \u001B[0mtokens\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtoken\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m             \u001B[1;31m# Sample\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 68\u001B[1;33m             \u001B[0mwt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchoice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     69\u001B[0m             \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moutput\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mwt\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m             \u001B[0mcontext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mwt\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mmtrand.pyx\u001B[0m in \u001B[0;36mnumpy.random.mtrand.RandomState.choice\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "lm_odia[3, deltas[0]].generate(context=['ଦୂରରେ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dump lm to file\n",
    "with open(os.path.join('ngram.lm.pkl'), 'wb') as f:\n",
    "    s = dill.dumps(lm_odia[3, deltas[0]])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}